%! TEX program = LuaLaTeX 
\documentclass[12pt, a4paper, twoside]{article}
\usepackage{format}
% Do not alter above

% Metadata: put your article information here 
\newcommand{\jtitle}{An Alternative Approach to Regulating Artificial Intelligence}
\newcommand{\jauthor}{Person C}
\newcommand{\jaffiliation}{some school}

% Editors will change these fields after acceptance 
\newcommand{\jvolume}{3}
\newcommand{\jyear}{2026}
\newcommand{\jdoi}{10.17613/82c3s-nac44}  

% References should be placed in refs.bib and cited with \autocite{<source>}
% Quotations can be placed in quote environments: \begin{quote}<your quote>\end{quote}
% Footnotes can be added with \footnote{<your footnote>}

% Your Content

\begin{document}

\maketitle{}

Much like the Internet revolution, the rise of artificial intelligence (AI) is changing how we live and work, with profound and far-reaching implications for the global economy, culture, and politics. At the same time, this change has spurred concerns, such as job displacement, bias, misinformation, and privacy, leading many to call for increased AI regulation \autocite{Meltzer2023USShouldRegulateAI}. More specifically, many have called for the regulation of particular (\cites{Biden2023EOAI}{AUDA-NEPAD2023WhitePaperAI}). In this essay, however, I argue against such regulations, advocating for a risk-based approach to regulate harmful technologies.

There are two main issues with technology-based regulation of AI: the lack of a clear definition and negative economic impacts.

First, “artificial intelligence” is an ill-defined term. In everyday language, AI typically refers to Large Language Models (LLMs) such as ChatGPT \autocite[p.\ 2]{Henman2020ImprovingPublicServicesAI}. However, there are other forms of AI, such as expert systems, which many proponents of technology-based regulation dismiss as being “just a bunch of if-statements” \autocite[p.\ 4]{Braun2024WhyAINotRegulated}. Nonetheless, this broad range of applications makes it nearly impossible to create a definition of AI that is both precise and comprehensive enough for effective regulation. Without a common definition of AI, regulation becomes impractical.

Second, regulations hamper innovation and hurt economies. Several studies found that regulations cut down the number of new firms, slow employment growth, and reduce innovation, all of which are key to increasing productivity and promoting economic growth (\cites[pp.\ 7--11]{BaileyThomas2017RegulatingAwayCompetition}[p.\ 45]{AghionEtAl2023RegulationInnovation}). The increased costs of regulation also prevent small firms from challenging larger ones, thereby stifling competition \autocite{Carney2012RegulationsProtectEntrenched}. Under the guise of promoting safety, entrenched businesses use regulations to maintain dominance in the market.

Clearly, any attempt to directly regulate AI is problematic. However, there is an alternative: risk-based regulation, i.e., regulating a wide range of technologies based on their risk level, irrespective of the type of technology. This risk-based approach holds many advantages over technology-based regulation, as it can account for the specific circumstances in which a technology is used, as well as having minimal impact on innovation and economic growth (\cites{MarcinekEtAl2024RANDAIActPrimer}{Bradford2023RaceToRegulateAI}). For example, instead of a technology-based ban on all facial recognition software, a risk-based approach might allow its use in highly controlled security settings, such as airports, while prohibiting its use for general surveillance in public spaces. Furthermore, with a risk-based approach that focuses only on high-risk applications, the regulatory burden for low-risk applications of AI is reduced, encouraging their development and deployment \autocite[p..\ 4--6]{Ebers2024RiskBasedEUAIACT}. Recently, the EU has put this approach into practice with the so-called “AI Act” (\emph{Artificial Intelligence Act}). Although the act lacks a risk-reward analysis and a concrete definition for “risk,” it represents a significant step forward in AI regulation, offering a potential model for other jurisdictions to imitate.

As the use of AI across the world becomes progressively more prevalent, it becomes increasingly important to regulate its use and prevent its abuse. Ultimately, it is through adaptable, risk-based regulations that we can ensure that AI serves humanity's best interests in the years to come.

\printbibliography

\end{document}

